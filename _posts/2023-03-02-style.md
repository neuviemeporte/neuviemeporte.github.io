---
layout: post
title: Discourse on Style
category: sw-eng
---

The XVIII century French naturalist, [Georges-Louis Leclerc](https://en.wikipedia.org/wiki/Georges-Louis_Leclerc,_Comte_de_Buffon), wrote in his _Discours sur le style_: "Writing well consists of thinking, feeling and expressing well, of clarity of mind, soul and taste... The style is the man himself." Programmers write code in a rigid language that puts bounds on our expression, but on the flip side it makes our intent understandable to computers. However, there is still room left for a touch of individual flair between the lines, and after doing software development for a couple years, you get a subjective "feel" for what constitues well-written code, if not exactly the ability to tell at a glance who wrote it - but such cases are also not unheard of (see below). I'm going to discuss the importance of style, but also how I think enforcing an oppressive style can negatively influence your project.

So it is acknowledged that code can posess style, but how does it exhibit itself? On the one hand, there is something I would call *structural style*. You read the code and it makes sense, the intent is clear and the flow of control is self-evident. Somebody gave thought to what they were doing and took care to cover the possible (and even some impossible) scenarios that the program could encounter at runtime, so errors are checked and handled properly. The code is neatly laid out and separated into manageable units (classes, functions, whatever). The functions and variables have meaningful names which correspond to whatever it is they are supposed to be doing. Wherever something surprising happens, there is a comment in the code that clearly documents the need for departing from the neatness, usually to account for some hardware quirk, or interfacing with a crusty old system that needs special handling. It's just overall nice. You get the idea. I won't be talking about that kind of style.

On the other hand is everything that does not have to do with structuring your code nicely, although there will always be some overlap. I realize the dichotomy is somewhat forced, but please bear with me. This kind of style involves deciding on what will be the maximum line length in characters, by how many spaces or tabs you indent your lines, whether your names will use [camelCase](https://en.wikipedia.org/wiki/Camel_case) or [snake_case](https://en.wikipedia.org/wiki/Snake_case), do you put your '{'-s on the same line as the function name, or on a separate one and so on. I do not have a good name for this kind of style, so let's just call it *annoying style*. ðŸ˜‰ It brings some measure of organization, and reading code with inconsistent or non-existent indentation is a strain on the eyes, but mostly it's orthogonal to the code having good structure (you can have nicely formatted code with horrible structure), and adherence to it comes at a cost of frustration to the developer, so there you have it. Annoying style.

Now, computers do not care about style of any kind. With the exception of some programming languages which actually use indentation as part of their syntax (Python, Fortran), as long as the code tells the computer what to do properly, it could be a convoluted mess, all written in a single long line of code, with no hint of structure whatsoever. Indeed, that is often what happens after the program code is compiled into executable (binary) form, especially with modern, optimizing compilers. Your nice code will be broken down, rearranged, transformed beyond recognition, because that form will actually be the most optimal for the machine to execute efficiently. That is why [reverse engineering](https://neuviemeporte.github.io/f15-se2/2022/12/09/reversing-1.html) is so hard and why automatic [decompilation](https://en.wikipedia.org/wiki/Decompiler) is not feasible outside of some limited cases. What we call "style" is only a means of making the code more readable to puny humans. And, as with any other human preference, the actual guidelines as to what is preferred, are extremely subjective, and ultimately it is a waste of time to argue whether one bracing convention is better than another - it will depend on who you ask, and people will come up with ridiculous "objective" justifications for their preference, then defend if zealously. So, if ever possible, avoid being drawn into these types of dicussions.

Some projects will not prescribe any style. I've worked on one where management required developers to submit patches in Word documents, so that managers would be able to open the code and "see" what the programmers were doing. Managers don't have editors that can open .cpp files installed on their computers, but they do have Word, so that was the way things were done. I'm not sure what they were expecting to gather from that code, but perhaps they could [count the lines](https://en.wikipedia.org/wiki/Source_lines_of_code) and determine which developer is the most profilic? In any case, that code had to be pasted back into a source file and fed into the compiler at some point, and nobody could be bothered to properly align it, and using an automated [linter](https://en.wikipedia.org/wiki/Lint_(software)) was beyond the realm of conceptualization for the people in the organization - nobody had the time, or cared. In the end, the code looked something like this:

{% highlight cpp %}
 class GetInterger {
              int getInterger()
              {
doSomething_completelyUn_related(

      );
  if   (x  ==1) return 1;
   else  if  (x== 3)
{
   return 2;
      }
    else { return x; }

}
void setInterger(int value)       
  { x  =  value; }
      private: int x;
                              };
{% endhighlight %}

I really wish I was kidding. But, if nothing else, this example showcases why it's hard to read and understand code with inconsistent formatting. I tried fixing some of it up as I was working on it, but there was so much code (probably because the managers were counting the lines), nobody else cared, and introducing changes into the source control or build system like running a linter was met with trepidation ("you will break the things!"), that I gave up. After fixing the indentation, making the bracing consistent and fixing the spelling mistakes, the code could look like this:

{% highlight cpp %}
class GetInteger {
private: 
    int x;

public:
    int doSomethingAndGetInteger() {
        doSomethingCompletelyUnrelated();
        if (x == 1) {
            return 1;
        }
        else if (x == 3) {
            // I have no idea why, but I need to preserve the original behaviour
            // while cleaning up, so it's risky to change.
            return 2; 
        }
        else { 
            return x; 
        }
    }

    void setInteger(int value) {
        x = value;
    }
};
{% endhighlight %}

This is a lot of work, is error prone, nobody will thank you for it if it works, and you will get in trouble if you break things by mistake. So don't bother and just move on, unless you have no choice. Ultimately, this code is completely useless, and depending on the exact circumstances, it could probably be replaced with a global integer value that they are wrapping in a class for no reason and then getting and setting just as it was a simple value:

{% highlight cpp %}
int numberOfThings;

// here's how we use it
void somewhereElse() {
    doSomethingCompletelyUnrelated();
    // get value from the global variable
    int thingCount = numberOfThings;
    // process the special case
    if (thingCount == 3) {
        // is this really still necessary?
        thingCount = 2;
    }
    // do something with the value
    processThings(thingCount);
    // set the global value to something else,
    // presumably we have processed all the things
    numberOfThings = 0;
}
{% endhighlight %}

There, done. It may also be questionable, but at least it's better than the original. Or is it? Again, depends on who you ask. To the people who have been working on this project for a long time, and getting their "Intergers" that way for years, you may just as well be the devil himself, a troublemaking outsider at the worst, or a clueless junior neophyte at best if you dare touch it. Style, the eternal subjective subject of fervent debate. Yaaawn.

So, we may agree that *some* degree of style is desirable. If everybody is required to follow a common set of rules, at least we will avoid having our code look like Swiss cheese, and hopefully that will make it easier to read, modify and maintain. Savvy teams will create their own style guide, or pick a well-known set of reasonable rules like the [Google style guide](https://google.github.io/styleguide/) for their programming language. It may be a little annoying, but modern tools like a good code editor or [IDE](https://en.wikipedia.org/wiki/Integrated_development_environment) help maintain proper indentation, some can even be programmed with a set of more complicated rules so you can make your bracing etc. compliant with a push of a button. You could even make the templates for the most commonly used editors available for download. Also, as previously mentioned, you could put a linter on the receiving end of your revision control and sanitize all code that's coming in. Progress and profit for everyone!

Question is, can you overdo it? Can you make your style guide needlessly oppressive, have the rules be hard or impossible to automate, and make your code look like it's been written in the 1970s? Well, sure you can! I realize all of this is of course subjective, but here are some of my favourite pet peeves.

- line length

{% highlight cpp %}
int someFunction() {
    /* We really need
     * our lines to 
     * be short.
     */
    becauseWe(cannot);
    afford("monitors"
        "that display"
        "more than 30"
        "characters "
        "on one line);
    if (we_need_to) {
        goDeeper(this,
            "becomes"
            "even"
            "more"
            "difficu"
            "lt");
    }
}
{% endhighlight %}

When limited by a style guide, this will usually be 80 characters, because that was the typical width of a [text terminal](https://en.wikipedia.org/wiki/Computer_terminal) in the 70s or something, but sometimes it can go lower. This makes it hard to maintain longer strings, comments and more complicated conditions, especially at deeper indentation levels - you will need to break your lines, and rewrap them every time you make a change (which is why it's best to apply the style as the last step before pushing the code to the repository). Usually the justification given (if any) is that Some Peopleâ„¢ are still editing code in 80-char wide terminal windows, or Some Toolsâ„¢ only support lines of limited length. Well, I should say those people need to catch up with the times, and those tools need to be updated or eliminated. Don't make me bounce off an invisible line that isn't there since circa 1990 while I'm trying to get my work done.

- variables at beginning of block

{% highlight cpp %}
int someFunction() {
    int   all, variables, need;
    char  to, be, declared, at, the, top;
    float as, it, was, in_the, days, of, old;

    nowWeWillDoSomething();

    /* and when we actually need to use our variables later... */
    weWillInitializeThem();
    all = 1;
    andUseThem(all);
}
{% endhighlight %}

This is a stupid throwback to 1989 and ANSI C. The compilers were apparently only able to generate code manipulating the stack frame at the opening brace of the function, so all variables had to be declared in advance. This limitation was removed in C99. That is the year 1999, 24 years ago when I'm writing this. Now you can do something:

{% highlight cpp %}
int someFunction() {

    iWillDo();
    whatNeedsToBeDone();
    toPrepare();

    /* and when I need a value, it will be declared, initialized */
    int value = 1;
    andUsed(value);
}
{% endhighlight %}

This puts the variables closer to the place where they are going to be used, so you do not need to jump around the function (especially if it's long) to peek at the declaration, and also it will not be possible to use that variable (especially uninitialized, i.e. without being assigned a value) before it makes sense to - it will be a compilation error. Hardly anyone uses a pre-C99 compiler these days, so this rule is just there to piss you off, or possibly because some senior dev gets irked when they see code that reminds them it's not the 80s anymore.

- single return

Back in the bad old days, you were not allowed to return from a function early, such as when encountering an error that made it impossible to proceed. I don't even know why, I don't think it was a limitation that was present in C89, but I guess what you did in assembly code was write a routine with a `RET` instruction at the end, and that made it clear where the routine ends. Single entrypoint, single return, bam, nice and simple. In assembly, it's natural and expected to use jumps in the code, so this was a common pattern. In higher level languages however, using gratuitous jumps such as a goto are [considered harmful](https://en.wikipedia.org/wiki/Goto#Criticism) as they obstruct the view of the flow of control, and can lead to [spaghetti code](https://en.wikipedia.org/wiki/Spaghetti_code). They still have some use, and remain in the language:

{% highlight cpp %}
void someFunction() {
    for (something) {
        while (somethingElse) {
            switch (whatever) {
            case error:
                /* if we are deep in some nested hierarchy, 
                 * it might make sense to just use goto 
                 * to jump out if needed */
                goto handle_error;
            }
        }
    }

    return true;

handle_error:
    doSomeHandling();
    return false;
}
{% endhighlight %}

However, some people will insist that you use gotos and jump through hoops to avoid having more than one return per function:

{% highlight cpp %}
void someFunction() {
    if (we_have_an_error)
        goto out;

    doSomething();

    if (other_error)
        goto out;

    int x = getValue();
    if (x == unexpected)
        goto out;

out:
    return;
}
{% endhighlight %}

This hides the intent of the code (especially if the label has a non-obvious name), introduces non-linear execution patterns for no good reason, and is hard to follow in more complicated functions. Also, it makes it awkward and easy to make mistakes at the end of the function if there is an error label, and a regular out label, extra care needs to be taken not to fall into one or the other unexpectedly. Just let me return whenever I need to, don't make me jump through hoops for no good reason, because it does not make the code run faster or the intent clearer. Honestly, I can't understand how anyone claiming to be a programmer can say with a straight face that a return in the middle of a function is somehow "confusing", especially compared to jumping 200 lines below where who the hell knows what happens. I got an error, I'm done, I'm out of here. Just get over it.

{% highlight cpp %}
{% endhighlight %}




- double indentation on continuation lines
- no modern C/C++ features
- disallowed assign and check




https://retrocomputing.stackexchange.com/questions/5341/how-did-people-use-ed/5343#5343

